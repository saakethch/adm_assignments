{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "648d6b4f",
   "metadata": {},
   "source": [
    "# Snowpark For Python -- Advertising Spend and ROI Prediction\n",
    "\n",
    "### Objective\n",
    "In this session, we will train a Linear Regression model to predict future ROI (Return On Investment) of variable ad spend budgets across multiple channels including search, video, social media, and email using Snowpark for Python and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bfbd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import IntegerType, StringType, StructType, FloatType, StructField, DateType, Variant\n",
    "from snowflake.snowpark.functions import udf, sum, col,array_construct,month,year,call_udf,lit\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc71d39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : \n",
      "Role                        : \n",
      "Database                    : \n",
      "Schema                      : \n",
      "Warehouse                   : \n",
      "Snowflake version           : \n",
      "Snowpark for Python version : \n"
     ]
    }
   ],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('select current_user(), current_role(), current_database(), current_schema(), current_version(), current_warehouse()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : '.format(snowflake_environment[0][0]))\n",
    "print('Role                        : '.format(snowflake_environment[0][1]))\n",
    "print('Database                    : '.format(snowflake_environment[0][2]))\n",
    "print('Schema                      : '.format(snowflake_environment[0][3]))\n",
    "print('Warehouse                   : '.format(snowflake_environment[0][5]))\n",
    "print('Snowflake version           : '.format(snowflake_environment[0][4]))\n",
    "print('Snowpark for Python version : '.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212a3660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT  *  FROM (campaign_spend)'], 'post_actions': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_df_spend = session.table('campaign_spend')\n",
    "snow_df_spend.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47096641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------\n",
      "|\"CAMPAIGN\"  |\"CHANNEL\"  |\"DATE\"  |\"TOTAL_CLICKS\"  |\"TOTAL_COST\"  |\"ADS_SERVED\"  |\n",
      "----------------------------------------------------------------------------------\n",
      "|            |           |        |                |              |              |\n",
      "----------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[QueryRecord(query_id='01aa9247-0000-fdc7-0000-000394de817d', sql_text='SELECT  *  FROM campaign_spend LIMIT 10')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Action sends the DF SQL for execution\n",
    "# Note: history object provides the query ID which can be helpful for debugging as well as the SQL query executed on the server\n",
    "with session.query_history() as history:\n",
    "    snow_df_spend.show()\n",
    "history.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f81242",
   "metadata": {},
   "source": [
    "### Total Spend per Channel per Month\n",
    "Let's transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cb6fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "|\"YEAR\"  |\"MONTH\"  |\"CHANNEL\"  |\"TOTAL_COST\"  |\n",
      "-----------------------------------------------\n",
      "|        |         |           |              |\n",
      "-----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stats per Month per Channel\n",
    "snow_df_spend_per_channel = snow_df_spend.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n",
    "    with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n",
    "\n",
    "snow_df_spend_per_channel.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7aae8",
   "metadata": {},
   "source": [
    "#### Pivot on Channel\n",
    "Let's further transform the campaign spend data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions. This transformation will enable us to join with the revenue table such that we will have our input features and target variable in a single table for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e9407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "|\"YEAR\"  |\"MONTH\"  |\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\n",
      "---------------------------------------------------------------------------\n",
      "|        |         |                 |                |         |         |\n",
      "---------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_spend_per_month = snow_df_spend_per_channel.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n",
    "snow_df_spend_per_month = snow_df_spend_per_month.select(\n",
    "    col(\"YEAR\"),\n",
    "    col(\"MONTH\"),\n",
    "    col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n",
    "    col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n",
    "    col(\"'video'\").as_(\"VIDEO\"),\n",
    "    col(\"'email'\").as_(\"EMAIL\")\n",
    ")\n",
    "snow_df_spend_per_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923419c",
   "metadata": {},
   "source": [
    "#### Total Revenue per Month\n",
    "Now let's load revenue table and transform the data into revenue per year/month using group_by and agg() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a59e475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "|\"YEAR\"  |\"MONTH\"  |\"REVENUE\"  |\n",
      "--------------------------------\n",
      "|        |         |           |\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_revenue = session.table('monthly_revenue')\n",
    "snow_df_revenue_per_month = snow_df_revenue.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n",
    "snow_df_revenue_per_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc61e944",
   "metadata": {},
   "source": [
    "#### Join Total Spend and Total Revenue per Month\n",
    "Next let's join this revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ffec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------\n",
      "|\"YEAR\"  |\"MONTH\"  |\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\"REVENUE\"  |\n",
      "---------------------------------------------------------------------------------------\n",
      "|        |         |                 |                |         |         |           |\n",
      "---------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_spend_and_revenue_per_month = snow_df_spend_per_month.join(snow_df_revenue_per_month, [\"YEAR\",\"MONTH\"])\n",
    "snow_df_spend_and_revenue_per_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc090a3",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> Examine Snowpark DataFrame Query and Execution Plan <<<<<<<<<<\n",
    "Snowpark makes is really convenient to look at the DataFrame query and execution plan using explain() Snowpark DataFrame function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9879ffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------DATAFRAME EXECUTION PLAN----------\n",
      "Query List:\n",
      "1.\n",
      "SELECT  *  FROM (( SELECT \"YEAR\" AS \"YEAR\", \"MONTH\" AS \"MONTH\", \"SEARCH_ENGINE\" AS \"SEARCH_ENGINE\", \"SOCIAL_MEDIA\" AS \"SOCIAL_MEDIA\", \"VIDEO\" AS \"VIDEO\", \"EMAIL\" AS \"EMAIL\" FROM ( SELECT \"YEAR\", \"MONTH\", \"'search_engine'\" AS \"SEARCH_ENGINE\", \"'social_media'\" AS \"SOCIAL_MEDIA\", \"'video'\" AS \"VIDEO\", \"'email'\" AS \"EMAIL\" FROM ( SELECT  *  FROM ( SELECT  *  FROM ( SELECT  *  FROM ( SELECT \"YEAR(DATE)\" AS \"YEAR\", \"MONTH(DATE)\" AS \"MONTH\", \"CHANNEL\", \"TOTAL_COST\" FROM ( SELECT year(\"DATE\") AS \"YEAR(DATE)\", month(\"DATE\") AS \"MONTH(DATE)\", \"CHANNEL\", sum(\"TOTAL_COST\") AS \"TOTAL_COST\" FROM ( SELECT  *  FROM campaign_spend) GROUP BY year(\"DATE\"), month(\"DATE\"), \"CHANNEL\")) ORDER BY \"YEAR\" ASC NULLS FIRST, \"MONTH\" ASC NULLS FIRST) PIVOT (sum(\"TOTAL_COST\") FOR \"CHANNEL\" IN ('search_engine', 'social_media', 'video', 'email'))) ORDER BY \"YEAR\" ASC NULLS FIRST, \"MONTH\" ASC NULLS FIRST))) AS SNOWPARK_TEMP_TABLE_WZLR9FZ30F INNER JOIN ( SELECT \"YEAR\" AS \"YEAR\", \"MONTH\" AS \"MONTH\", \"REVENUE\" AS \"REVENUE\" FROM ( SELECT \"YEAR\", \"MONTH\", \"SUM(REVENUE)\" AS \"REVENUE\" FROM ( SELECT  *  FROM ( SELECT \"YEAR\", \"MONTH\", sum(\"REVENUE\") AS \"SUM(REVENUE)\" FROM ( SELECT  *  FROM monthly_revenue) GROUP BY \"YEAR\", \"MONTH\") ORDER BY \"YEAR\" ASC NULLS FIRST, \"MONTH\" ASC NULLS FIRST))) AS SNOWPARK_TEMP_TABLE_FVHX2TQYZ4 USING (YEAR, MONTH))\n",
      "Logical Execution Plan:\n",
      "GlobalStats:\n",
      "    partitionsTotal=0\n",
      "    partitionsAssigned=0\n",
      "    bytesAssigned=0\n",
      "Operations:\n",
      "1:0     ->Result  EXTRACT(year from CAMPAIGN_SPEND.DATE), EXTRACT(month from CAMPAIGN_SPEND.DATE), 'search_engine', 'social_media', 'video', 'email', SUM(MONTHLY_REVENUE.REVENUE)  \n",
      "1:1          ->Generator  0  \n",
      "\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "snow_df_spend_and_revenue_per_month.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d3ce2",
   "metadata": {},
   "source": [
    "### Model Training in Snowflake\n",
    "#### Features and Target\n",
    "At this point we are ready to perform the following actions to save features and target for model training.\n",
    "\n",
    "Delete rows with missing values\n",
    "Exclude columns we don't need for modeling\n",
    "Save features into a Snowflake table called MARKETING_BUDGETS_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0f33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "|\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\"REVENUE\"  |\n",
      "--------------------------------------------------------------------\n",
      "|                 |                |         |         |           |\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Delete rows with missing values\n",
    "snow_df_spend_and_revenue_per_month = snow_df_spend_and_revenue_per_month.dropna()\n",
    "\n",
    "# Exclude columns we don't need for modeling\n",
    "snow_df_spend_and_revenue_per_month = snow_df_spend_and_revenue_per_month.drop(['YEAR','MONTH'])\n",
    "\n",
    "# Save features into a Snowflake table call MARKETING_BUDGETS_FEATURES\n",
    "snow_df_spend_and_revenue_per_month.write.mode('overwrite').save_as_table('MARKETING_BUDGETS_FEATURES')\n",
    "snow_df_spend_and_revenue_per_month.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb3ec70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT  *  FROM (MARKETING_BUDGETS_FEATURES)'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = session.table('MARKETING_BUDGETS_FEATURES')\n",
    "tst.queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd115956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "|\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\"REVENUE\"  |\n",
      "--------------------------------------------------------------------\n",
      "|                 |                |         |         |           |\n",
      "--------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[QueryRecord(query_id='01aa9247-0000-fdc6-0000-000394de6315', sql_text='SELECT  *  FROM MARKETING_BUDGETS_FEATURES LIMIT 10')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with session.query_history() as history:\n",
    "    tst.show()\n",
    "history.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2358e",
   "metadata": {},
   "source": [
    "#### Python function to train a Linear Regression model using scikit-learn\n",
    "Let's create a Python function that uses scikit-learn and other packages which are already included in Snowflake Anaconda channel and therefore available on the server-side when executing the Python function as a Stored Procedure running in Snowflake.\n",
    "\n",
    "This function takes the following as parameters:\n",
    "\n",
    "session: Snowflake Session object.\n",
    "features_table: Name of the table that holds the features and target variable.\n",
    "number_of_folds: Number of cross validation folds used in GridSearchCV.\n",
    "polynomial_features_degress: PolynomialFeatures as a preprocessing step.\n",
    "train_accuracy_threshold: Accuracy thresholds for train dataset. This values is used to determine if the model should be saved.\n",
    "test_accuracy_threshold: Accuracy thresholds for test dataset. This values is used to determine if the model should be saved.\n",
    "save_model: Boolean that determines if the model should be saved provided the accuracy thresholds are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28e65f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_revenue_prediction_model(\n",
    "    session: Session, \n",
    "    features_table: str, \n",
    "    number_of_folds: int, \n",
    "    polynomial_features_degrees: int, \n",
    "    train_accuracy_threshold: float, \n",
    "    test_accuracy_threshold: float, \n",
    "    save_model: bool) -> Variant:\n",
    "    \n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "    import os\n",
    "    from joblib import dump\n",
    "\n",
    "    # Load features\n",
    "    df = session.table(features_table).to_pandas()\n",
    "\n",
    "    # Preprocess the Numeric columns\n",
    "    # We apply PolynomialFeatures and StandardScaler preprocessing steps to the numeric columns\n",
    "    # NOTE: High degrees can cause overfitting.\n",
    "    numeric_features = ['SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL']\n",
    "    numeric_transformer = Pipeline(steps=[('poly',PolynomialFeatures(degree = polynomial_features_degrees)),('scaler', StandardScaler())])\n",
    "\n",
    "    # Combine the preprocessed step together using the Column Transformer module\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "    # The next step is the integrate the features we just preprocessed with our Machine Learning algorithm to enable us to build a model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', LinearRegression())])\n",
    "    parameteres = {}\n",
    "\n",
    "    X = df.drop('REVENUE', axis = 1)\n",
    "    y = df['REVENUE']\n",
    "\n",
    "    # Split dataset into training and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "    # Use GridSearch to find the best fitting model based on number_of_folds folds\n",
    "    model = GridSearchCV(pipeline, param_grid=parameteres, cv=number_of_folds)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    train_r2_score = model.score(X_train, y_train)\n",
    "    test_r2_score = model.score(X_test, y_test)\n",
    "\n",
    "    model_saved = False\n",
    "\n",
    "    if save_model:\n",
    "        if train_r2_score >= train_accuracy_threshold and test_r2_score >= test_accuracy_threshold:\n",
    "            # Upload trained model to a stage\n",
    "            model_output_dir = '/tmp'\n",
    "            model_file = os.path.join(model_output_dir, 'model.joblib')\n",
    "            dump(model, model_file)\n",
    "            session.file.put(model_file,\"@dash_models\",overwrite=True)\n",
    "            model_saved = True\n",
    "\n",
    "    # Return model R2 score on train and test data\n",
    "    return {\"R2 score on Train\": train_r2_score,\n",
    "            \"R2 threshold on Train\": train_accuracy_threshold,\n",
    "            \"R2 score on Test\": test_r2_score,\n",
    "            \"R2 threshold on Test\": test_accuracy_threshold,\n",
    "            \"Model saved\": model_saved}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54e1192",
   "metadata": {},
   "source": [
    "### Test Python function before deploying it as a Stored Procedure on Snowflake\n",
    "Since we're in test mode, we will set save_model = False so that the model is not saved just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e54c7ea6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m test_accuracy_threshold \u001b[39m=\u001b[39m \u001b[39m0.85\u001b[39m\n\u001b[0;32m      5\u001b[0m save_model \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_revenue_prediction_model(\n\u001b[0;32m      8\u001b[0m     session,\n\u001b[0;32m      9\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mMARKETING_BUDGETS_FEATURES\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m     cross_validaton_folds,\n\u001b[0;32m     11\u001b[0m     polynomial_features_degrees,\n\u001b[0;32m     12\u001b[0m     train_accuracy_threshold,\n\u001b[0;32m     13\u001b[0m     test_accuracy_threshold,\n\u001b[0;32m     14\u001b[0m     save_model)\n",
      "Cell \u001b[1;32mIn[13], line 42\u001b[0m, in \u001b[0;36mtrain_revenue_prediction_model\u001b[1;34m(session, features_table, number_of_folds, polynomial_features_degrees, train_accuracy_threshold, test_accuracy_threshold, save_model)\u001b[0m\n\u001b[0;32m     39\u001b[0m y \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mREVENUE\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     41\u001b[0m \u001b[39m# Split dataset into training and test\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state \u001b[39m=\u001b[39;49m \u001b[39m42\u001b[39;49m)\n\u001b[0;32m     44\u001b[0m \u001b[39m# Use GridSearch to find the best fitting model based on number_of_folds folds\u001b[39;00m\n\u001b[0;32m     45\u001b[0m model \u001b[39m=\u001b[39m GridSearchCV(pipeline, param_grid\u001b[39m=\u001b[39mparameteres, cv\u001b[39m=\u001b[39mnumber_of_folds)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m )\n\u001b[0;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "cross_validaton_folds = 10\n",
    "polynomial_features_degrees = 2\n",
    "train_accuracy_threshold = 0.85\n",
    "test_accuracy_threshold = 0.85\n",
    "save_model = False\n",
    "\n",
    "train_revenue_prediction_model(\n",
    "    session,\n",
    "    'MARKETING_BUDGETS_FEATURES',\n",
    "    cross_validaton_folds,\n",
    "    polynomial_features_degrees,\n",
    "    train_accuracy_threshold,\n",
    "    test_accuracy_threshold,\n",
    "    save_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a3f58",
   "metadata": {},
   "source": [
    "### Create Stored Procedure to deploy model training code on Snowflake\n",
    "Assuming the testing is complete and we're satisfied with the model, let's register the model training Python function as a Snowpark Python Stored Procedure by supplying the packages (snowflake-snowpark-python,scikit-learn, and joblib) it will need and use during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e752987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x29ce08f3d60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(\n",
    "    func=train_revenue_prediction_model,\n",
    "    name=\"train_revenue_prediction_model\",\n",
    "    packages=['snowflake-snowpark-python','scikit-learn','joblib'],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@dash_sprocs\",\n",
    "    replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a88da3",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> Examine Query History in Snowsight <<<<<<<<<<\n",
    "Execute Stored Procedure to train model and deploy it on Snowflake\n",
    "Now we're ready to train the model and save it onto a Snowflake stage so let's set save_model = True and run/execute the Stored Procedure using session.call() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d582f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to execute query [queryID: 01aa9248-0000-fdc7-0000-000394de81ad] CALL train_revenue_prediction_model('MARKETING_BUDGETS_FEATURES', 10 :: INT, 2 :: INT, '0.85' :: FLOAT, '0.85' :: FLOAT, True :: BOOLEAN)\n",
      "100357 (P0000): Python Interpreter Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"_udf_code.py\", line 7, in compute\n",
      "  File \"C:\\Users\\15512\\AppData\\Local\\Temp\\ipykernel_22328\\2873238866.py\", line 42, in train_revenue_prediction_model\n",
      "  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n",
      "    n_train, n_test = _validate_shuffle_split(\n",
      "  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n",
      "    raise ValueError(\n",
      "ValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n",
      " in function TRAIN_REVENUE_PREDICTION_MODEL with handler compute\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01aa9248-0000-fdc7-0000-000394de81ad: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"C:\\Users\\15512\\AppData\\Local\\Temp\\ipykernel_22328\\2873238866.py\", line 42, in train_revenue_prediction_model\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n in function TRAIN_REVENUE_PREDICTION_MODEL with handler compute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m test_accuracy_threshold \u001b[39m=\u001b[39m \u001b[39m0.85\u001b[39m\n\u001b[0;32m      5\u001b[0m save_model \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(session\u001b[39m.\u001b[39;49mcall(\u001b[39m'\u001b[39;49m\u001b[39mtrain_revenue_prediction_model\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m                     \u001b[39m'\u001b[39;49m\u001b[39mMARKETING_BUDGETS_FEATURES\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m                     cross_validaton_folds,\n\u001b[0;32m     10\u001b[0m                     polynomial_features_degrees,\n\u001b[0;32m     11\u001b[0m                     train_accuracy_threshold,\n\u001b[0;32m     12\u001b[0m                     test_accuracy_threshold,\n\u001b[0;32m     13\u001b[0m                     save_model))\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\session.py:1805\u001b[0m, in \u001b[0;36mSession.call\u001b[1;34m(self, sproc_name, *args)\u001b[0m\n\u001b[0;32m   1803\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCALL \u001b[39m\u001b[39m{\u001b[39;00msproc_name\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(sql_args)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1804\u001b[0m set_api_call_source(df, \u001b[39m\"\u001b[39m\u001b[39mSession.call\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1805\u001b[0m \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mcollect()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\telemetry.py:138\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    137\u001b[0m     \u001b[39mwith\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mquery_history() \u001b[39mas\u001b[39;00m query_history:\n\u001b[1;32m--> 138\u001b[0m         result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    139\u001b[0m     plan \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_select_statement \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_plan\n\u001b[0;32m    140\u001b[0m     api_calls \u001b[39m=\u001b[39m [\n\u001b[0;32m    141\u001b[0m         \u001b[39m*\u001b[39mplan\u001b[39m.\u001b[39mapi_calls,\n\u001b[0;32m    142\u001b[0m         {TelemetryField\u001b[39m.\u001b[39mNAME\u001b[39m.\u001b[39mvalue: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame.\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    143\u001b[0m     ]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\dataframe.py:546\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[1;34m(self, statement_params, block)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39m@df_collect_api_telemetry\u001b[39m\n\u001b[0;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollect\u001b[39m(\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, statement_params: Optional[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, block: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    533\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[List[Row], AsyncJob]:\n\u001b[0;32m    534\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39m    list of :class:`Row` objects.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39m        :meth:`collect_nowait()`\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_collect_with_tag_no_telemetry(\n\u001b[0;32m    547\u001b[0m         statement_params\u001b[39m=\u001b[39;49mstatement_params, block\u001b[39m=\u001b[39;49mblock\n\u001b[0;32m    548\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\dataframe.py:581\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[1;34m(self, statement_params, block, data_type)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[0;32m    572\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    573\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[39m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[39m# query tag is set properly.\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    582\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plan,\n\u001b[0;32m    583\u001b[0m         block\u001b[39m=\u001b[39;49mblock,\n\u001b[0;32m    584\u001b[0m         data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[0;32m    585\u001b[0m         _statement_params\u001b[39m=\u001b[39;49mcreate_or_update_statement_params_with_query_tag(\n\u001b[0;32m    586\u001b[0m             statement_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mquery_tag, SKIP_LEVELS_THREE\n\u001b[0;32m    587\u001b[0m         ),\n\u001b[0;32m    588\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:406\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[1;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m is_in_stored_procedure() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m block:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    404\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsync query is not supported in stored procedure yet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m     )\n\u001b[1;32m--> 406\u001b[0m result_set, result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result_set(\n\u001b[0;32m    407\u001b[0m     plan, to_pandas, to_iter, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, block\u001b[39m=\u001b[39;49mblock, data_type\u001b[39m=\u001b[39;49mdata_type\n\u001b[0;32m    408\u001b[0m )\n\u001b[0;32m    409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[0;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m result_set\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\analyzer\\snowflake_plan.py:156\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     ne \u001b[39m=\u001b[39m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[0;32m    154\u001b[0m         e\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m ne\u001b[39m.\u001b[39mwith_traceback(tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\analyzer\\snowflake_plan.py:89\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     88\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m     \u001b[39mexcept\u001b[39;00m snowflake\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mProgrammingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     91\u001b[0m         tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:494\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[1;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m holder, id_ \u001b[39min\u001b[39;00m placeholders\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    493\u001b[0m     final_query \u001b[39m=\u001b[39m final_query\u001b[39m.\u001b[39mreplace(holder, id_)\n\u001b[1;32m--> 494\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[0;32m    495\u001b[0m     final_query,\n\u001b[0;32m    496\u001b[0m     to_pandas,\n\u001b[0;32m    497\u001b[0m     to_iter \u001b[39mand\u001b[39;49;00m (i \u001b[39m==\u001b[39;49m \u001b[39mlen\u001b[39;49m(plan\u001b[39m.\u001b[39;49mqueries) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[0;32m    498\u001b[0m     is_ddl_on_temp_object\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mis_ddl_on_temp_object,\n\u001b[0;32m    499\u001b[0m     block\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_last,\n\u001b[0;32m    500\u001b[0m     data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[0;32m    501\u001b[0m     async_job_plan\u001b[39m=\u001b[39;49mplan,\n\u001b[0;32m    502\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    503\u001b[0m )\n\u001b[0;32m    504\u001b[0m placeholders[query\u001b[39m.\u001b[39mquery_id_place_holder] \u001b[39m=\u001b[39m (\n\u001b[0;32m    505\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mquery_id\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    507\u001b[0m result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor\u001b[39m.\u001b[39mdescription\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:104\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:98\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[0;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    102\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:333\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m     query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    335\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:317\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m--> 317\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[0;32m    319\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    321\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\cursor.py:827\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream, num_statements)\u001b[0m\n\u001b[0;32m    823\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[0;32m    824\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    825\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[0;32m    826\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[1;32m--> 827\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[0;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:275\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[0;32m    254\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m],\n\u001b[0;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[0;32m    276\u001b[0m         connection,\n\u001b[0;32m    277\u001b[0m         cursor,\n\u001b[0;32m    278\u001b[0m         error_class,\n\u001b[0;32m    279\u001b[0m         error_value,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[0;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[0;32m    283\u001b[0m             error_class,\n\u001b[0;32m    284\u001b[0m             error_value,\n\u001b[0;32m    285\u001b[0m         )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:330\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[1;32m--> 330\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:209\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_errorhandler\u001b[39m(\n\u001b[0;32m    193\u001b[0m     connection: SnowflakeConnection,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m    197\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Default error handler that raises an error.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m        A Snowflake error.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(\n\u001b[0;32m    210\u001b[0m         msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    211\u001b[0m         errno\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    212\u001b[0m         sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    213\u001b[0m         sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    214\u001b[0m         done_format_msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    215\u001b[0m         connection\u001b[39m=\u001b[39mconnection,\n\u001b[0;32m    216\u001b[0m         cursor\u001b[39m=\u001b[39mcursor,\n\u001b[0;32m    217\u001b[0m     )\n",
      "\u001b[1;31mSnowparkSQLException\u001b[0m: (1304): 01aa9248-0000-fdc7-0000-000394de81ad: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"C:\\Users\\15512\\AppData\\Local\\Temp\\ipykernel_22328\\2873238866.py\", line 42, in train_revenue_prediction_model\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n in function TRAIN_REVENUE_PREDICTION_MODEL with handler compute"
     ]
    }
   ],
   "source": [
    "cross_validaton_folds = 10\n",
    "polynomial_features_degrees = 2\n",
    "train_accuracy_threshold = 0.85\n",
    "test_accuracy_threshold = 0.85\n",
    "save_model = True\n",
    "\n",
    "print(session.call('train_revenue_prediction_model',\n",
    "                    'MARKETING_BUDGETS_FEATURES',\n",
    "                    cross_validaton_folds,\n",
    "                    polynomial_features_degrees,\n",
    "                    train_accuracy_threshold,\n",
    "                    test_accuracy_threshold,\n",
    "                    save_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc5298a",
   "metadata": {},
   "source": [
    "### Create Stored Procedure to deploy model training code on Snowflake\n",
    "Assuming the testing is complete and we're satisfied with the model, let's register the model training Python function as a Snowpark Python Stored Procedure by supplying the packages (snowflake-snowpark-python,scikit-learn, and joblib) it will need and use during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec96479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x29ce14bab80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(\n",
    "    func=train_revenue_prediction_model,\n",
    "    name=\"train_revenue_prediction_model\",\n",
    "    packages=['snowflake-snowpark-python','scikit-learn','joblib'],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@dash_sprocs\",\n",
    "    replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47027bd7",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> Examine Query History in Snowsight <<<<<<<<<<\n",
    "Execute Stored Procedure to train model and deploy it on Snowflake\n",
    "Now we're ready to train the model and save it onto a Snowflake stage so let's set save_model = True and run/execute the Stored Procedure using session.call() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82c8dc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to execute query [queryID: 01aa9248-0000-fdc7-0000-000394de81c5] CALL train_revenue_prediction_model('MARKETING_BUDGETS_FEATURES', 10 :: INT, 2 :: INT, '0.85' :: FLOAT, '0.85' :: FLOAT, True :: BOOLEAN)\n",
      "100357 (P0000): Python Interpreter Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"_udf_code.py\", line 7, in compute\n",
      "  File \"C:\\Users\\15512\\AppData\\Local\\Temp\\ipykernel_22328\\2873238866.py\", line 42, in train_revenue_prediction_model\n",
      "  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n",
      "    n_train, n_test = _validate_shuffle_split(\n",
      "  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n",
      "    raise ValueError(\n",
      "ValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n",
      " in function TRAIN_REVENUE_PREDICTION_MODEL with handler compute\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01aa9248-0000-fdc7-0000-000394de81c5: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"C:\\Users\\15512\\AppData\\Local\\Temp\\ipykernel_22328\\2873238866.py\", line 42, in train_revenue_prediction_model\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n in function TRAIN_REVENUE_PREDICTION_MODEL with handler compute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m test_accuracy_threshold \u001b[39m=\u001b[39m \u001b[39m0.85\u001b[39m\n\u001b[0;32m      5\u001b[0m save_model \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(session\u001b[39m.\u001b[39;49mcall(\u001b[39m'\u001b[39;49m\u001b[39mtrain_revenue_prediction_model\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m                     \u001b[39m'\u001b[39;49m\u001b[39mMARKETING_BUDGETS_FEATURES\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m                     cross_validaton_folds,\n\u001b[0;32m     10\u001b[0m                     polynomial_features_degrees,\n\u001b[0;32m     11\u001b[0m                     train_accuracy_threshold,\n\u001b[0;32m     12\u001b[0m                     test_accuracy_threshold,\n\u001b[0;32m     13\u001b[0m                     save_model))\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\session.py:1805\u001b[0m, in \u001b[0;36mSession.call\u001b[1;34m(self, sproc_name, *args)\u001b[0m\n\u001b[0;32m   1803\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCALL \u001b[39m\u001b[39m{\u001b[39;00msproc_name\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(sql_args)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1804\u001b[0m set_api_call_source(df, \u001b[39m\"\u001b[39m\u001b[39mSession.call\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1805\u001b[0m \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mcollect()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\telemetry.py:138\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    137\u001b[0m     \u001b[39mwith\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mquery_history() \u001b[39mas\u001b[39;00m query_history:\n\u001b[1;32m--> 138\u001b[0m         result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    139\u001b[0m     plan \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_select_statement \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_plan\n\u001b[0;32m    140\u001b[0m     api_calls \u001b[39m=\u001b[39m [\n\u001b[0;32m    141\u001b[0m         \u001b[39m*\u001b[39mplan\u001b[39m.\u001b[39mapi_calls,\n\u001b[0;32m    142\u001b[0m         {TelemetryField\u001b[39m.\u001b[39mNAME\u001b[39m.\u001b[39mvalue: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame.\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    143\u001b[0m     ]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\dataframe.py:546\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[1;34m(self, statement_params, block)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[39m@df_collect_api_telemetry\u001b[39m\n\u001b[0;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollect\u001b[39m(\n\u001b[0;32m    532\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, statement_params: Optional[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, block: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    533\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[List[Row], AsyncJob]:\n\u001b[0;32m    534\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39m    list of :class:`Row` objects.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[39m        :meth:`collect_nowait()`\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_collect_with_tag_no_telemetry(\n\u001b[0;32m    547\u001b[0m         statement_params\u001b[39m=\u001b[39;49mstatement_params, block\u001b[39m=\u001b[39;49mblock\n\u001b[0;32m    548\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\dataframe.py:581\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[1;34m(self, statement_params, block, data_type)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[0;32m    572\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    573\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[39m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[39m# query tag is set properly.\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    582\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plan,\n\u001b[0;32m    583\u001b[0m         block\u001b[39m=\u001b[39;49mblock,\n\u001b[0;32m    584\u001b[0m         data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[0;32m    585\u001b[0m         _statement_params\u001b[39m=\u001b[39;49mcreate_or_update_statement_params_with_query_tag(\n\u001b[0;32m    586\u001b[0m             statement_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mquery_tag, SKIP_LEVELS_THREE\n\u001b[0;32m    587\u001b[0m         ),\n\u001b[0;32m    588\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:406\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[1;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39mif\u001b[39;00m is_in_stored_procedure() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m block:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    404\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsync query is not supported in stored procedure yet\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m     )\n\u001b[1;32m--> 406\u001b[0m result_set, result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result_set(\n\u001b[0;32m    407\u001b[0m     plan, to_pandas, to_iter, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, block\u001b[39m=\u001b[39;49mblock, data_type\u001b[39m=\u001b[39;49mdata_type\n\u001b[0;32m    408\u001b[0m )\n\u001b[0;32m    409\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m block:\n\u001b[0;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m result_set\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\analyzer\\snowflake_plan.py:156\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     ne \u001b[39m=\u001b[39m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[0;32m    154\u001b[0m         e\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m ne\u001b[39m.\u001b[39mwith_traceback(tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\analyzer\\snowflake_plan.py:89\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     88\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m     \u001b[39mexcept\u001b[39;00m snowflake\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mProgrammingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     91\u001b[0m         tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:494\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[1;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m holder, id_ \u001b[39min\u001b[39;00m placeholders\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    493\u001b[0m     final_query \u001b[39m=\u001b[39m final_query\u001b[39m.\u001b[39mreplace(holder, id_)\n\u001b[1;32m--> 494\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[0;32m    495\u001b[0m     final_query,\n\u001b[0;32m    496\u001b[0m     to_pandas,\n\u001b[0;32m    497\u001b[0m     to_iter \u001b[39mand\u001b[39;49;00m (i \u001b[39m==\u001b[39;49m \u001b[39mlen\u001b[39;49m(plan\u001b[39m.\u001b[39;49mqueries) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[0;32m    498\u001b[0m     is_ddl_on_temp_object\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mis_ddl_on_temp_object,\n\u001b[0;32m    499\u001b[0m     block\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_last,\n\u001b[0;32m    500\u001b[0m     data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[0;32m    501\u001b[0m     async_job_plan\u001b[39m=\u001b[39;49mplan,\n\u001b[0;32m    502\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    503\u001b[0m )\n\u001b[0;32m    504\u001b[0m placeholders[query\u001b[39m.\u001b[39mquery_id_place_holder] \u001b[39m=\u001b[39m (\n\u001b[0;32m    505\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mquery_id\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    507\u001b[0m result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor\u001b[39m.\u001b[39mdescription\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:104\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:98\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[0;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    102\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:333\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m     query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    335\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:317\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m--> 317\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[0;32m    319\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    321\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\cursor.py:827\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream, num_statements)\u001b[0m\n\u001b[0;32m    823\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[0;32m    824\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    825\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[0;32m    826\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[1;32m--> 827\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[0;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:275\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[0;32m    254\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m],\n\u001b[0;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[0;32m    276\u001b[0m         connection,\n\u001b[0;32m    277\u001b[0m         cursor,\n\u001b[0;32m    278\u001b[0m         error_class,\n\u001b[0;32m    279\u001b[0m         error_value,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[0;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[0;32m    283\u001b[0m             error_class,\n\u001b[0;32m    284\u001b[0m             error_value,\n\u001b[0;32m    285\u001b[0m         )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:330\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[1;32m--> 330\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:209\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_errorhandler\u001b[39m(\n\u001b[0;32m    193\u001b[0m     connection: SnowflakeConnection,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m    197\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Default error handler that raises an error.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m        A Snowflake error.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(\n\u001b[0;32m    210\u001b[0m         msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    211\u001b[0m         errno\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    212\u001b[0m         sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    213\u001b[0m         sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    214\u001b[0m         done_format_msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    215\u001b[0m         connection\u001b[39m=\u001b[39mconnection,\n\u001b[0;32m    216\u001b[0m         cursor\u001b[39m=\u001b[39mcursor,\n\u001b[0;32m    217\u001b[0m     )\n",
      "\u001b[1;31mSnowparkSQLException\u001b[0m: (1304): 01aa9248-0000-fdc7-0000-000394de81c5: 100357 (P0000): Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"C:\\Users\\15512\\AppData\\Local\\Temp\\ipykernel_22328\\2873238866.py\", line 42, in train_revenue_prediction_model\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2562, in train_test_split\n    n_train, n_test = _validate_shuffle_split(\n  File \"/usr/lib/python_udf/c44bd28c1f111d4dac440cea14fff60ed16c45e517074f7a33374de715f9e7db/lib/python3.8/site-packages/sklearn/model_selection/_split.py\", line 2236, in _validate_shuffle_split\n    raise ValueError(\nValueError: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.\n in function TRAIN_REVENUE_PREDICTION_MODEL with handler compute"
     ]
    }
   ],
   "source": [
    "cross_validaton_folds = 10\n",
    "polynomial_features_degrees = 2\n",
    "train_accuracy_threshold = 0.85\n",
    "test_accuracy_threshold = 0.85\n",
    "save_model = True\n",
    "\n",
    "print(session.call('train_revenue_prediction_model',\n",
    "                    'MARKETING_BUDGETS_FEATURES',\n",
    "                    cross_validaton_folds,\n",
    "                    polynomial_features_degrees,\n",
    "                    train_accuracy_threshold,\n",
    "                    test_accuracy_threshold,\n",
    "                    save_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7746d5",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> Examine Query History in Snowsight <<<<<<<<<<\n",
    "Create Scalar User-Defined Function (UDF) for inference\n",
    "Now to deploy this model for inference, let's create and register a Snowpark Python UDF and add the trained model as a dependency. Once registered, getting new predictions is as simple as calling the function by passing in data.\n",
    "\n",
    "NOTE: Scalar UDFs operate on a single row / set of data points and are great for online inference in real-time. And this UDF is called from the Streamlit App. See Snowpark_Streamlit_Revenue_Prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a51f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "# Add trained model and Python packages from Snowflake Anaconda channel available on the server-side as UDF dependencies\n",
    "session.add_import('@dash_models/model.joblib.gz')\n",
    "session.add_packages('pandas','joblib','scikit-learn==1.1.1')\n",
    "\n",
    "@udf(name='predict_roi',session=session,replace=True,is_permanent=True,stage_location='@dash_udfs')\n",
    "def predict_roi(budget_allocations: list) -> float:\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    from joblib import load\n",
    "    import sklearn\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    model_file = import_dir + 'model.joblib.gz'\n",
    "    model = load(model_file)\n",
    "            \n",
    "    features = ['SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL']\n",
    "    df = pd.DataFrame([budget_allocations], columns=features)\n",
    "    roi = abs(model.predict(df)[0])\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf75422",
   "metadata": {},
   "source": [
    "### Call Scalar User-Defined Function (UDF) for inference on new data\n",
    "Once the UDF is registered, getting new predictions is as simple as calling the call_udf() Snowpark Python function and passing in new datapoints.\n",
    "\n",
    "Let's create a SnowPark DataFrame with some sample data and call the UDF to get new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a574c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to execute query [queryID: 01aa9248-0000-fdc7-0000-000394de81d5]  SELECT \"SEARCH_ENGINE\", \"SOCIAL_MEDIA\", \"VIDEO\", \"EMAIL\", predict_roi(array_construct(\"SEARCH_ENGINE\", \"SOCIAL_MEDIA\", \"VIDEO\", \"EMAIL\")) AS \"PREDICTED_ROI\" FROM ( SELECT $1 AS \"SEARCH_ENGINE\", $2 AS \"SOCIAL_MEDIA\", $3 AS \"VIDEO\", $4 AS \"EMAIL\" FROM  VALUES (250000 :: INT, 250000 :: INT, 200000 :: INT, 450000 :: INT), (500000 :: INT, 500000 :: INT, 500000 :: INT, 500000 :: INT), (8500 :: INT, 9500 :: INT, 2000 :: INT, 500 :: INT)) LIMIT 10\n",
      "002140 (42601): SQL compilation error:\n",
      "Unknown function PREDICT_ROI\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01aa9248-0000-fdc7-0000-000394de81d5: 002140 (42601): SQL compilation error:\nUnknown function PREDICT_ROI",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_df \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mcreate_dataframe([[\u001b[39m250000\u001b[39m,\u001b[39m250000\u001b[39m,\u001b[39m200000\u001b[39m,\u001b[39m450000\u001b[39m],[\u001b[39m500000\u001b[39m,\u001b[39m500000\u001b[39m,\u001b[39m500000\u001b[39m,\u001b[39m500000\u001b[39m],[\u001b[39m8500\u001b[39m,\u001b[39m9500\u001b[39m,\u001b[39m2000\u001b[39m,\u001b[39m500\u001b[39m]], \n\u001b[0;32m      2\u001b[0m                                     schema\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mSEARCH_ENGINE\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSOCIAL_MEDIA\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mVIDEO\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mEMAIL\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m test_df\u001b[39m.\u001b[39;49mselect(\n\u001b[0;32m      4\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mSEARCH_ENGINE\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mSOCIAL_MEDIA\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mVIDEO\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mEMAIL\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      5\u001b[0m     call_udf(\u001b[39m\"\u001b[39;49m\u001b[39mpredict_roi\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[0;32m      6\u001b[0m     array_construct(col(\u001b[39m\"\u001b[39;49m\u001b[39mSEARCH_ENGINE\u001b[39;49m\u001b[39m\"\u001b[39;49m), col(\u001b[39m\"\u001b[39;49m\u001b[39mSOCIAL_MEDIA\u001b[39;49m\u001b[39m\"\u001b[39;49m), col(\u001b[39m\"\u001b[39;49m\u001b[39mVIDEO\u001b[39;49m\u001b[39m\"\u001b[39;49m), col(\u001b[39m\"\u001b[39;49m\u001b[39mEMAIL\u001b[39;49m\u001b[39m\"\u001b[39;49m)))\u001b[39m.\u001b[39;49mas_(\u001b[39m\"\u001b[39;49m\u001b[39mPREDICTED_ROI\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\telemetry.py:138\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    137\u001b[0m     \u001b[39mwith\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39mquery_history() \u001b[39mas\u001b[39;00m query_history:\n\u001b[1;32m--> 138\u001b[0m         result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    139\u001b[0m     plan \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_select_statement \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_plan\n\u001b[0;32m    140\u001b[0m     api_calls \u001b[39m=\u001b[39m [\n\u001b[0;32m    141\u001b[0m         \u001b[39m*\u001b[39mplan\u001b[39m.\u001b[39mapi_calls,\n\u001b[0;32m    142\u001b[0m         {TelemetryField\u001b[39m.\u001b[39mNAME\u001b[39m.\u001b[39mvalue: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataFrame.\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    143\u001b[0m     ]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\dataframe.py:2658\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, n, max_width, statement_params)\u001b[0m\n\u001b[0;32m   2639\u001b[0m \u001b[39m@df_collect_api_telemetry\u001b[39m\n\u001b[0;32m   2640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     statement_params: Optional[Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2646\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2647\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluates this DataFrame and prints out the first ``n`` rows with the\u001b[39;00m\n\u001b[0;32m   2648\u001b[0m \u001b[39m    specified maximum number of characters per column.\u001b[39;00m\n\u001b[0;32m   2649\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2655\u001b[0m \u001b[39m        statement_params: Dictionary of statement level parameters to be set while executing this action.\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2657\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m-> 2658\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_show_string(\n\u001b[0;32m   2659\u001b[0m             n,\n\u001b[0;32m   2660\u001b[0m             max_width,\n\u001b[0;32m   2661\u001b[0m             _statement_params\u001b[39m=\u001b[39;49mcreate_or_update_statement_params_with_query_tag(\n\u001b[0;32m   2662\u001b[0m                 statement_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49mquery_tag, SKIP_LEVELS_TWO\n\u001b[0;32m   2663\u001b[0m             ),\n\u001b[0;32m   2664\u001b[0m         )\n\u001b[0;32m   2665\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\dataframe.py:2774\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, max_width, **kwargs)\u001b[0m\n\u001b[0;32m   2771\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_plan\u001b[39m.\u001b[39mqueries[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msql\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mlower()\n\u001b[0;32m   2773\u001b[0m \u001b[39mif\u001b[39;00m is_sql_select_statement(query):\n\u001b[1;32m-> 2774\u001b[0m     result, meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mget_result_and_metadata(\n\u001b[0;32m   2775\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlimit(n)\u001b[39m.\u001b[39;49m_plan, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   2776\u001b[0m     )\n\u001b[0;32m   2777\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2778\u001b[0m     res, meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39m_conn\u001b[39m.\u001b[39mget_result_and_metadata(\n\u001b[0;32m   2779\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_plan, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m   2780\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:529\u001b[0m, in \u001b[0;36mServerConnection.get_result_and_metadata\u001b[1;34m(self, plan, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_result_and_metadata\u001b[39m(\n\u001b[0;32m    527\u001b[0m     \u001b[39mself\u001b[39m, plan: SnowflakePlan, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    528\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[Row], List[Attribute]]:\n\u001b[1;32m--> 529\u001b[0m     result_set, result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result_set(plan, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    530\u001b[0m     result \u001b[39m=\u001b[39m result_set_to_rows(result_set[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    531\u001b[0m     meta \u001b[39m=\u001b[39m convert_result_meta_to_attribute(result_meta)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\analyzer\\snowflake_plan.py:156\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    153\u001b[0m     ne \u001b[39m=\u001b[39m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[0;32m    154\u001b[0m         e\n\u001b[0;32m    155\u001b[0m     )\n\u001b[1;32m--> 156\u001b[0m     \u001b[39mraise\u001b[39;00m ne\u001b[39m.\u001b[39mwith_traceback(tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\analyzer\\snowflake_plan.py:89\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     88\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     90\u001b[0m     \u001b[39mexcept\u001b[39;00m snowflake\u001b[39m.\u001b[39mconnector\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mProgrammingError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     91\u001b[0m         tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:494\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[1;34m(self, plan, to_pandas, to_iter, block, data_type, **kwargs)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m holder, id_ \u001b[39min\u001b[39;00m placeholders\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    493\u001b[0m     final_query \u001b[39m=\u001b[39m final_query\u001b[39m.\u001b[39mreplace(holder, id_)\n\u001b[1;32m--> 494\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(\n\u001b[0;32m    495\u001b[0m     final_query,\n\u001b[0;32m    496\u001b[0m     to_pandas,\n\u001b[0;32m    497\u001b[0m     to_iter \u001b[39mand\u001b[39;49;00m (i \u001b[39m==\u001b[39;49m \u001b[39mlen\u001b[39;49m(plan\u001b[39m.\u001b[39;49mqueries) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[0;32m    498\u001b[0m     is_ddl_on_temp_object\u001b[39m=\u001b[39;49mquery\u001b[39m.\u001b[39;49mis_ddl_on_temp_object,\n\u001b[0;32m    499\u001b[0m     block\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m is_last,\n\u001b[0;32m    500\u001b[0m     data_type\u001b[39m=\u001b[39;49mdata_type,\n\u001b[0;32m    501\u001b[0m     async_job_plan\u001b[39m=\u001b[39;49mplan,\n\u001b[0;32m    502\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    503\u001b[0m )\n\u001b[0;32m    504\u001b[0m placeholders[query\u001b[39m.\u001b[39mquery_id_place_holder] \u001b[39m=\u001b[39m (\n\u001b[0;32m    505\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_last \u001b[39melse\u001b[39;00m result\u001b[39m.\u001b[39mquery_id\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    507\u001b[0m result_meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor\u001b[39m.\u001b[39mdescription\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:104\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:98\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[0;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m    100\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m    101\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m    102\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:333\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m     query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 333\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    335\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:317\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m--> 317\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[0;32m    319\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    321\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\cursor.py:827\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream, num_statements)\u001b[0m\n\u001b[0;32m    823\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[0;32m    824\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    825\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[0;32m    826\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[1;32m--> 827\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[0;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:275\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[0;32m    254\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m],\n\u001b[0;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[0;32m    276\u001b[0m         connection,\n\u001b[0;32m    277\u001b[0m         cursor,\n\u001b[0;32m    278\u001b[0m         error_class,\n\u001b[0;32m    279\u001b[0m         error_value,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[0;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[0;32m    283\u001b[0m             error_class,\n\u001b[0;32m    284\u001b[0m             error_value,\n\u001b[0;32m    285\u001b[0m         )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:330\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[1;32m--> 330\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment2\\env2\\lib\\site-packages\\snowflake\\connector\\errors.py:209\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_errorhandler\u001b[39m(\n\u001b[0;32m    193\u001b[0m     connection: SnowflakeConnection,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m    197\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Default error handler that raises an error.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m        A Snowflake error.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(\n\u001b[0;32m    210\u001b[0m         msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    211\u001b[0m         errno\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    212\u001b[0m         sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    213\u001b[0m         sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    214\u001b[0m         done_format_msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    215\u001b[0m         connection\u001b[39m=\u001b[39mconnection,\n\u001b[0;32m    216\u001b[0m         cursor\u001b[39m=\u001b[39mcursor,\n\u001b[0;32m    217\u001b[0m     )\n",
      "\u001b[1;31mSnowparkSQLException\u001b[0m: (1304): 01aa9248-0000-fdc7-0000-000394de81d5: 002140 (42601): SQL compilation error:\nUnknown function PREDICT_ROI"
     ]
    }
   ],
   "source": [
    "test_df = session.create_dataframe([[250000,250000,200000,450000],[500000,500000,500000,500000],[8500,9500,2000,500]], \n",
    "                                    schema=['SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL'])\n",
    "test_df.select(\n",
    "    'SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL', \n",
    "    call_udf(\"predict_roi\", \n",
    "    array_construct(col(\"SEARCH_ENGINE\"), col(\"SOCIAL_MEDIA\"), col(\"VIDEO\"), col(\"EMAIL\"))).as_(\"PREDICTED_ROI\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98611f84",
   "metadata": {},
   "source": [
    "### Create Vectorized User-Defined Function (UDF) using Batch API for inference\n",
    "Here we will leverage the Python UDF Batch API to create a vectorized UDF which takes a Pandas Dataframe as input. This means that each call to the UDF receives a set/batch of rows compared to a Scalar UDF which gets one row as input.\n",
    "\n",
    "First we will create a helper function load_model() that uses cachetools to make sure we only load the model once followed by batch_predict_roi() function that does the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d4a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "import cachetools\n",
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame\n",
    "\n",
    "# Add trained model and Python packages from Snowflake Anaconda channel available on the server-side as UDF dependencies\n",
    "session.add_import('@dash_models/model.joblib.gz')\n",
    "session.add_packages('pandas','joblib','scikit-learn','cachetools')\n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def load_model(filename):\n",
    "    import joblib\n",
    "    import sys\n",
    "    import os\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "\n",
    "    if import_dir:\n",
    "        with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "            m = joblib.load(file)\n",
    "            return m\n",
    "\n",
    "@udf(name='batch_predict_roi',session=session,replace=True,is_permanent=True,stage_location='@dash_udfs')\n",
    "def batch_predict_roi(budget_allocations_df: PandasDataFrame[int, int, int, int]) -> PandasSeries[float]:\n",
    "    import sklearn\n",
    "    budget_allocations_df.columns = ['SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL']\n",
    "    model = load_model('model.joblib.gz')\n",
    "    return abs(model.predict(budget_allocations_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8c8fa",
   "metadata": {},
   "source": [
    "### Call Vectorized User-Defined Function (UDF) using Batch API for inference on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e466d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "|\"SEARCH_ENGINE\"  |\"SOCIAL_MEDIA\"  |\"VIDEO\"  |\"EMAIL\"  |\"PREDICTED_ROI\"     |\n",
      "-----------------------------------------------------------------------------\n",
      "|250000           |250000          |200000   |450000   |4072491.441668165   |\n",
      "|500000           |500000          |500000   |500000   |3179613.166194177   |\n",
      "|8500             |9500            |2000     |500      |189866.83304722887  |\n",
      "-----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.select(\n",
    "    'SEARCH_ENGINE','SOCIAL_MEDIA','VIDEO','EMAIL', \n",
    "    call_udf(\"batch_predict_roi\", \n",
    "    col(\"SEARCH_ENGINE\"), col(\"SOCIAL_MEDIA\"), col(\"VIDEO\"), col(\"EMAIL\")).as_(\"PREDICTED_ROI\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c0771",
   "metadata": {},
   "source": [
    "### Automate Data Pipeline and Model (re)Training using Snowflake Tasks\n",
    "We can also optionally create Snowflake (Serverless or User-managed) Tasks to automate data pipelining and (re)training of the model on a set schedule.\n",
    "\n",
    "NOTE: Creating tasks using Snowpark Python API (instead of SQL) is on the roadmap. Stay tuned! Or, follow me on [Twitter]((https://twitter.com/iamontheinet)) to get the news before anyone else :)_\n",
    "\n",
    "#### Create Python Function for Data Pipeline and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cf49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline_feature_engineering(session: Session) -> str:\n",
    "\n",
    "  # DATA TRANSFORMATIONS\n",
    "  # Perform the following actions to transform the data\n",
    "\n",
    "  # Load the campaign spend data\n",
    "  snow_df_spend = session.table('campaign_spend')\n",
    "\n",
    "  # Transform the data so we can see total cost per year/month per channel using group_by() and agg() Snowpark DataFrame functions\n",
    "  snow_df_spend_per_channel = snow_df_spend.group_by(year('DATE'), month('DATE'),'CHANNEL').agg(sum('TOTAL_COST').as_('TOTAL_COST')).\\\n",
    "      with_column_renamed('\"YEAR(DATE)\"',\"YEAR\").with_column_renamed('\"MONTH(DATE)\"',\"MONTH\").sort('YEAR','MONTH')\n",
    "\n",
    "  # Transform the data so that each row will represent total cost across all channels per year/month using pivot() and sum() Snowpark DataFrame functions\n",
    "  snow_df_spend_per_month = snow_df_spend_per_channel.pivot('CHANNEL',['search_engine','social_media','video','email']).sum('TOTAL_COST').sort('YEAR','MONTH')\n",
    "  snow_df_spend_per_month = snow_df_spend_per_month.select(\n",
    "      col(\"YEAR\"),\n",
    "      col(\"MONTH\"),\n",
    "      col(\"'search_engine'\").as_(\"SEARCH_ENGINE\"),\n",
    "      col(\"'social_media'\").as_(\"SOCIAL_MEDIA\"),\n",
    "      col(\"'video'\").as_(\"VIDEO\"),\n",
    "      col(\"'email'\").as_(\"EMAIL\")\n",
    "  )\n",
    "\n",
    "  # Load revenue table and transform the data into revenue per year/month using group_by and agg() functions\n",
    "  snow_df_revenue = session.table('monthly_revenue')\n",
    "  snow_df_revenue_per_month = snow_df_revenue.group_by('YEAR','MONTH').agg(sum('REVENUE')).sort('YEAR','MONTH').with_column_renamed('SUM(REVENUE)','REVENUE')\n",
    "\n",
    "  # Join revenue data with the transformed campaign spend data so that our input features (i.e. cost per channel) and target variable (i.e. revenue) can be loaded into a single table for model training\n",
    "  snow_df_spend_and_revenue_per_month = snow_df_spend_per_month.join(snow_df_revenue_per_month, [\"YEAR\",\"MONTH\"])\n",
    "\n",
    "  # SAVE FEATURES And TARGET\n",
    "  # Perform the following actions to save features and target for model training\n",
    "\n",
    "  # Delete rows with missing values\n",
    "  snow_df_spend_and_revenue_per_month = snow_df_spend_and_revenue_per_month.dropna()\n",
    "\n",
    "  # Exclude columns we don't need for modeling\n",
    "  snow_df_spend_and_revenue_per_month = snow_df_spend_and_revenue_per_month.drop(['YEAR','MONTH'])\n",
    "\n",
    "  # Save features into a Snowflake table call MARKETING_BUDGETS_FEATURES\n",
    "  snow_df_spend_and_revenue_per_month.write.mode('overwrite').save_as_table('MARKETING_BUDGETS_FEATURES')\n",
    "\n",
    "  return \"SUCCESS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fa5a7",
   "metadata": {},
   "source": [
    "### Create Stored Procedure to deploy data pipelining feature engineeering code on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be7db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x1e1e4f189d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(\n",
    "    func=data_pipeline_feature_engineering,\n",
    "    name=\"data_pipeline_feature_engineering\",\n",
    "    packages=['snowflake-snowpark-python'],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@dash_sprocs\",\n",
    "    replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4d017",
   "metadata": {},
   "source": [
    "### Execute Stored Procedure to deploy data pipelining feature engineeering code on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602c7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "print(session.call('data_pipeline_feature_engineering'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d39ac",
   "metadata": {},
   "source": [
    "### Create Root/Parent Snowflake Task: Data pipelining and feature engineeering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eaa2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Task DATA_PIPELINE_FEATURE_ENGINEERING_TASK successfully created.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_data_pipeline_feature_engineering_task = \"\"\"\n",
    "CREATE OR REPLACE TASK data_pipeline_feature_engineering_task\n",
    "    WAREHOUSE = 'DASH_L'\n",
    "    SCHEDULE  = '1 MINUTE'\n",
    "AS\n",
    "    CALL data_pipeline_feature_engineering()\n",
    "\"\"\"\n",
    "session.sql(create_data_pipeline_feature_engineering_task).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36728967",
   "metadata": {},
   "source": [
    "### Create Child/Dependent Snowflake Task: Model training on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe442ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Task MODEL_TRAINING_TASK successfully created.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_training_task = \"\"\"\n",
    "CREATE OR REPLACE TASK model_training_task\n",
    "    WAREHOUSE = 'DASH_L'\n",
    "    AFTER data_pipeline_feature_engineering_task\n",
    "AS\n",
    "    CALL train_revenue_prediction_model('MARKETING_BUDGETS_FEATURES',10,2,0.85,0.85,True)\n",
    "\"\"\"\n",
    "session.sql(create_model_training_task).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57a2ef",
   "metadata": {},
   "source": [
    "### Resume Tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e889f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"alter task model_training_task resume\").collect()\n",
    "session.sql(\"alter task data_pipeline_feature_engineering_task resume\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d33a691",
   "metadata": {},
   "source": [
    "### Cleanup Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb0b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"alter task data_pipeline_feature_engineering_task suspend\").collect()\n",
    "session.sql(\"alter task model_training_task suspend\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949895ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9e1528eca729c7bba03b0df246038118aa3d2b1b7458199cbed6890b10284b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
