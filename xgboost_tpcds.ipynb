{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.snowpark\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import version as v\n",
    "import json \n",
    "\n",
    "with open('connection.json') as f:\n",
    "    data = json.load(f)\n",
    "    USERNAME = data['user']\n",
    "    PASSWORD = data['password']\n",
    "    SF_ACCOUNT = data['account']\n",
    "    SF_WH = data['warehouse']\n",
    "\n",
    "CONNECTION_PARAMETERS = {\n",
    "   \"account\": SF_ACCOUNT,\n",
    "   \"user\": USERNAME,\n",
    "   \"password\": PASSWORD,\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='SNOWFLAKE_SAMPLE_DATA already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''create database if not exists snowflake_sample_data from share sfc_samples.sample_data''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('CREATE DATABASE IF NOT EXISTS tpcds_xgboost').collect()\n",
    "session.sql('CREATE SCHEMA IF NOT EXISTS tpcds_xgboost.demo').collect()\n",
    "session.sql(\"create or replace warehouse FE_AND_INFERENCE_WH with warehouse_size='3X-LARGE'\").collect()\n",
    "session.sql(\"create or replace warehouse snowpark_opt_wh with warehouse_size = 'MEDIUM' warehouse_type = 'SNOWPARK-OPTIMIZED'\").collect()\n",
    "session.sql(\"alter warehouse snowpark_opt_wh set max_concurrency_level = 1\").collect()\n",
    "session.use_warehouse('FE_AND_INFERENCE_WH')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select either 100 or 10 for the TPC-DS Dataset size to use below. See (https://docs.snowflake.com/en/user-guide/sample-data-tpcds.html)[here] for more information If you choose 100, I recommend >= 3XL warehouse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPCDS_SIZE_PARAM = 10\n",
    "SNOWFLAKE_SAMPLE_DB = 'SNOWFLAKE_SAMPLE_DATA' # Name of Snowflake Sample Database might be different...\n",
    "\n",
    "if TPCDS_SIZE_PARAM == 100: \n",
    "    TPCDS_SCHEMA = 'TPCDS_SF100TCL'\n",
    "elif TPCDS_SIZE_PARAM == 10:\n",
    "    TPCDS_SCHEMA = 'TPCDS_SF10TCL'\n",
    "else:\n",
    "    raise ValueError(\"Invalid TPCDS_SIZE_PARAM selection\")\n",
    "    \n",
    "store_sales = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.store_sales')\n",
    "catalog_sales = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.catalog_sales') \n",
    "web_sales = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.web_sales') \n",
    "date = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.date_dim')\n",
    "dim_stores = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.store')\n",
    "customer = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.customer')\n",
    "address = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.customer_address')\n",
    "demo = session.table(f'{SNOWFLAKE_SAMPLE_DB}.{TPCDS_SCHEMA}.customer_demographics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We will aggregate sales by customer across all channels(web, store, catalogue) and join that to customer demographic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_sales_agged = store_sales.group_by('ss_customer_sk').agg(F.sum('ss_sales_price').as_('total_sales'))\n",
    "web_sales_agged = web_sales.group_by('ws_bill_customer_sk').agg(F.sum('ws_sales_price').as_('total_sales'))\n",
    "catalog_sales_agged = catalog_sales.group_by('cs_bill_customer_sk').agg(F.sum('cs_sales_price').as_('total_sales'))\n",
    "store_sales_agged = store_sales_agged.rename('ss_customer_sk', 'customer_sk')\n",
    "web_sales_agged = web_sales_agged.rename('ws_bill_customer_sk', 'customer_sk')\n",
    "catalog_sales_agged = catalog_sales_agged.rename('cs_bill_customer_sk', 'customer_sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = store_sales_agged.union_all(web_sales_agged)\n",
    "total_sales = total_sales.union_all(catalog_sales_agged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = total_sales.group_by('customer_sk').agg(F.sum('total_sales').as_('total_sales'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = customer.select('c_customer_sk','c_current_hdemo_sk', 'c_current_addr_sk', 'c_customer_id', 'c_birth_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMER_SK\"  |\"C_CURRENT_HDEMO_SK\"  |\"C_CURRENT_ADDR_SK\"  |\"C_CUSTOMER_ID\"   |\"C_BIRTH_YEAR\"  |\"CA_ADDRESS_SK\"  |\"CA_ZIP\"  |\"CD_DEMO_SK\"  |\"CD_GENDER\"  |\"CD_MARITAL_STATUS\"  |\"CD_CREDIT_RATING\"  |\"CD_EDUCATION_STATUS\"  |\"CD_DEP_COUNT\"  |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|60566488       |6846                  |18830487             |AAAAAAAAINLCMJDA  |1952            |18830487         |NULL      |6846          |F            |D                    |Good                |Advanced Degree        |1               |\n",
      "|60566489       |3564                  |14404870             |AAAAAAAAJNLCMJDA  |1988            |14404870         |50587     |3564          |F            |S                    |High Risk           |Unknown                |0               |\n",
      "|60566490       |4684                  |17765836             |AAAAAAAAKNLCMJDA  |1954            |17765836         |30519     |4684          |F            |S                    |Unknown             |Unknown                |0               |\n",
      "|60566491       |761                   |29082657             |AAAAAAAALNLCMJDA  |1932            |29082657         |38883     |761           |M            |M                    |Good                |Unknown                |0               |\n",
      "|60566492       |3967                  |19167218             |AAAAAAAAMNLCMJDA  |1987            |19167218         |38048     |3967          |M            |W                    |High Risk           |4 yr Degree            |0               |\n",
      "|60566493       |6861                  |11443476             |AAAAAAAANNLCMJDA  |1983            |11443476         |29101     |6861          |M            |M                    |Good                |Primary                |1               |\n",
      "|60566494       |4652                  |19206825             |AAAAAAAAONLCMJDA  |1952            |19206825         |26534     |4652          |F            |M                    |Unknown             |2 yr Degree            |0               |\n",
      "|60566495       |3022                  |15555307             |AAAAAAAAPNLCMJDA  |1924            |15555307         |70499     |3022          |F            |M                    |High Risk           |Secondary              |0               |\n",
      "|60566496       |4689                  |5762350              |AAAAAAAAAOLCMJDA  |1967            |5762350          |67752     |4689          |M            |U                    |Unknown             |Unknown                |0               |\n",
      "|60566497       |3948                  |9041952              |AAAAAAAABOLCMJDA  |1970            |9041952          |76867     |3948          |F            |W                    |High Risk           |College                |0               |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer = customer.join(address.select('ca_address_sk', 'ca_zip'), customer['c_current_addr_sk'] == address['ca_address_sk'] )\n",
    "customer = customer.join(demo.select('cd_demo_sk', 'cd_gender', 'cd_marital_status', 'cd_credit_rating', 'cd_education_status', 'cd_dep_count'),\n",
    "                                customer['c_current_hdemo_sk'] == demo['cd_demo_sk'] )\n",
    "customer = customer.rename('c_customer_sk', 'customer_sk')\n",
    "customer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = total_sales.join(customer, on='customer_sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_database('tpcds_xgboost')\n",
    "session.use_schema('demo')\n",
    "final_df.write.mode('overwrite').save_as_table('feature_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package snowflake-snowpark-python in the local environment is 1.2.0, which does not fit the criteria for the requirement snowflake-snowpark-python. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package scikit-learn in the local environment is 1.2.1, which does not fit the criteria for the requirement scikit-learn. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package joblib in the local environment is 1.2.0, which does not fit the criteria for the requirement joblib. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package cachetools in the local environment is 5.3.0, which does not fit the criteria for the requirement cachetools. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package xgboost in the local environment is 1.7.4, which does not fit the criteria for the requirement xgboost. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "session.add_packages('snowflake-snowpark-python', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'cachetools', 'xgboost', 'joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Stage area ML_MODELS successfully created.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('CREATE OR REPLACE STAGE ml_models ').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "def train_model(session: snowflake.snowpark.Session) -> float:\n",
    "    snowdf = session.table(\"feature_store\")\n",
    "    snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "    snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82) \n",
    "\n",
    "    # save the train and test sets as time stamped tables in Snowflake \n",
    "    snowdf_train.write.mode(\"overwrite\").save_as_table(\"tpcds_xgboost.demo.tpc_TRAIN\")\n",
    "    snowdf_test.write.mode(\"overwrite\").save_as_table(\"tpcds_xgboost.demo.tpc_TEST\")\n",
    "    train_x = snowdf_train.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
    "    train_y = snowdf_train.select(\"TOTAL_SALES\").to_pandas()\n",
    "    test_x = snowdf_test.drop(\"TOTAL_SALES\").to_pandas()\n",
    "    test_y = snowdf_test.select(\"TOTAL_SALES\").to_pandas()\n",
    "    cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
    "    num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', num_pipeline, num_cols),\n",
    "                  ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ])\n",
    "\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                        ('xgboost', XGBRegressor())])\n",
    "    pipe.fit(train_x, train_y)\n",
    "\n",
    "    test_preds = pipe.predict(test_x)\n",
    "    mape = mean_absolute_percentage_error(test_y, test_preds)\n",
    "    model_file = os.path.join('/tmp', 'model.joblib')\n",
    "    joblib.dump(pipe, model_file)\n",
    "    session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to execute query [queryID: 01ab085c-3200-b026-0000-00027c064021] \n",
      "CREATE OR REPLACE \n",
      "  PROCEDURE  xgboost_sproc()\n",
      "RETURNS FLOAT\n",
      "LANGUAGE PYTHON \n",
      "RUNTIME_VERSION=3.8\n",
      "\n",
      "PACKAGES=('snowflake-snowpark-python','scikit-learn','pandas','numpy','joblib','cachetools','xgboost','cloudpickle==2.0.0')\n",
      "HANDLER='compute'\n",
      "EXECUTE AS OWNER\n",
      "\n",
      "\n",
      "AS $$\n",
      "import pickle\n",
      "\n",
      "func = pickle.loads(bytes.fromhex('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'))\n",
      "# The following comment contains the source code generated by snowpark-python for explanatory purposes.\n",
      "# import joblib\n",
      "# import os\n",
      "# import os.path\n",
      "# from sklearn.compose._column_transformer import ColumnTransformer\n",
      "# from sklearn.impute._base import SimpleImputer\n",
      "# from sklearn.metrics._regression import mean_absolute_percentage_error\n",
      "# from sklearn.pipeline import Pipeline\n",
      "# from sklearn.preprocessing._data import StandardScaler\n",
      "# from sklearn.preprocessing._encoders import OneHotEncoder\n",
      "# from xgboost.sklearn import XGBRegressor\n",
      "# def train_model(session: snowflake.snowpark.Session) -> float:\n",
      "#     snowdf = session.table(\"feature_store\")\n",
      "#     snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
      "#     snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82) \n",
      "#\n",
      "#     # save the train and test sets as time stamped tables in Snowflake \n",
      "#     snowdf_train.write.mode(\"overwrite\").save_as_table(\"tpcds_xgboost.demo.tpc_TRAIN\")\n",
      "#     snowdf_test.write.mode(\"overwrite\").save_as_table(\"tpcds_xgboost.demo.tpc_TEST\")\n",
      "#     train_x = snowdf_train.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
      "#     train_y = snowdf_train.select(\"TOTAL_SALES\").to_pandas()\n",
      "#     test_x = snowdf_test.drop(\"TOTAL_SALES\").to_pandas()\n",
      "#     test_y = snowdf_test.select(\"TOTAL_SALES\").to_pandas()\n",
      "#     cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
      "#     num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
      "#\n",
      "#     num_pipeline = Pipeline([\n",
      "#             ('imputer', SimpleImputer(strategy=\"median\")),\n",
      "#             ('std_scaler', StandardScaler()),\n",
      "#         ])\n",
      "#\n",
      "#     preprocessor = ColumnTransformer(\n",
      "#     transformers=[('num', num_pipeline, num_cols),\n",
      "#                   ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ])\n",
      "#\n",
      "#     pipe = Pipeline([('preprocessor', preprocessor), \n",
      "#                         ('xgboost', XGBRegressor())])\n",
      "#     pipe.fit(train_x, train_y)\n",
      "#\n",
      "#     test_preds = pipe.predict(test_x)\n",
      "#     mape = mean_absolute_percentage_error(test_y, test_preds)\n",
      "#     model_file = os.path.join('/tmp', 'model.joblib')\n",
      "#     joblib.dump(pipe, model_file)\n",
      "#     session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
      "#     return mape\n",
      "#\n",
      "# func = train_model\n",
      "\n",
      "def compute(session):\n",
      "    return func(session)\n",
      "$$\n",
      "\n",
      "\n",
      "391529 (42501): SQL compilation error: Anaconda terms must be accepted by ORGADMIN to use Anaconda 3rd party packages. Please follow the instructions at https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda.\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 01ab085c-3200-b026-0000-00027c064021: 391529 (42501): SQL compilation error: Anaconda terms must be accepted by ORGADMIN to use Anaconda 3rd party packages. Please follow the instructions at https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m session\u001b[39m.\u001b[39muse_warehouse(\u001b[39m'\u001b[39m\u001b[39msnowpark_opt_wh\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_model_sp \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49msproc(train_model, session\u001b[39m=\u001b[39;49msession, replace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, is_permanent\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mxgboost_sproc\u001b[39;49m\u001b[39m\"\u001b[39;49m, stage_location\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m@ml_models\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Switch to Snowpark Optimized Warehouse for training and to run the stored proc\u001b[39;00m\n\u001b[0;32m      4\u001b[0m train_model_sp(session\u001b[39m=\u001b[39msession)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\functions.py:3738\u001b[0m, in \u001b[0;36msproc\u001b[1;34m(func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, session, parallel, statement_params, execute_as, strict, source_code_display)\u001b[0m\n\u001b[0;32m   3720\u001b[0m     \u001b[39mreturn\u001b[39;00m functools\u001b[39m.\u001b[39mpartial(\n\u001b[0;32m   3721\u001b[0m         session\u001b[39m.\u001b[39msproc\u001b[39m.\u001b[39mregister,\n\u001b[0;32m   3722\u001b[0m         return_type\u001b[39m=\u001b[39mreturn_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3735\u001b[0m         source_code_display\u001b[39m=\u001b[39msource_code_display,\n\u001b[0;32m   3736\u001b[0m     )\n\u001b[0;32m   3737\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3738\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49msproc\u001b[39m.\u001b[39;49mregister(\n\u001b[0;32m   3739\u001b[0m         func,\n\u001b[0;32m   3740\u001b[0m         return_type\u001b[39m=\u001b[39;49mreturn_type,\n\u001b[0;32m   3741\u001b[0m         input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3742\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   3743\u001b[0m         is_permanent\u001b[39m=\u001b[39;49mis_permanent,\n\u001b[0;32m   3744\u001b[0m         stage_location\u001b[39m=\u001b[39;49mstage_location,\n\u001b[0;32m   3745\u001b[0m         imports\u001b[39m=\u001b[39;49mimports,\n\u001b[0;32m   3746\u001b[0m         packages\u001b[39m=\u001b[39;49mpackages,\n\u001b[0;32m   3747\u001b[0m         replace\u001b[39m=\u001b[39;49mreplace,\n\u001b[0;32m   3748\u001b[0m         if_not_exists\u001b[39m=\u001b[39;49mif_not_exists,\n\u001b[0;32m   3749\u001b[0m         parallel\u001b[39m=\u001b[39;49mparallel,\n\u001b[0;32m   3750\u001b[0m         statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[0;32m   3751\u001b[0m         execute_as\u001b[39m=\u001b[39;49mexecute_as,\n\u001b[0;32m   3752\u001b[0m         strict\u001b[39m=\u001b[39;49mstrict,\n\u001b[0;32m   3753\u001b[0m         source_code_display\u001b[39m=\u001b[39;49msource_code_display,\n\u001b[0;32m   3754\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:453\u001b[0m, in \u001b[0;36mStoredProcedureRegistration.register\u001b[1;34m(self, func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, parallel, execute_as, strict, statement_params, source_code_display)\u001b[0m\n\u001b[0;32m    448\u001b[0m check_register_args(\n\u001b[0;32m    449\u001b[0m     TempObjectType\u001b[39m.\u001b[39mPROCEDURE, name, is_permanent, stage_location, parallel\n\u001b[0;32m    450\u001b[0m )\n\u001b[0;32m    452\u001b[0m \u001b[39m# register stored procedure\u001b[39;00m\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_register_sp(\n\u001b[0;32m    454\u001b[0m     func,\n\u001b[0;32m    455\u001b[0m     return_type,\n\u001b[0;32m    456\u001b[0m     input_types,\n\u001b[0;32m    457\u001b[0m     name,\n\u001b[0;32m    458\u001b[0m     stage_location,\n\u001b[0;32m    459\u001b[0m     imports,\n\u001b[0;32m    460\u001b[0m     packages,\n\u001b[0;32m    461\u001b[0m     replace,\n\u001b[0;32m    462\u001b[0m     if_not_exists,\n\u001b[0;32m    463\u001b[0m     parallel,\n\u001b[0;32m    464\u001b[0m     strict,\n\u001b[0;32m    465\u001b[0m     statement_params\u001b[39m=\u001b[39;49mstatement_params,\n\u001b[0;32m    466\u001b[0m     execute_as\u001b[39m=\u001b[39;49mexecute_as,\n\u001b[0;32m    467\u001b[0m     api_call_source\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mStoredProcedureRegistration.register\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    468\u001b[0m     source_code_display\u001b[39m=\u001b[39;49msource_code_display,\n\u001b[0;32m    469\u001b[0m )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:680\u001b[0m, in \u001b[0;36mStoredProcedureRegistration._do_register_sp\u001b[1;34m(self, func, return_type, input_types, sp_name, stage_location, imports, packages, replace, if_not_exists, parallel, strict, source_code_display, statement_params, execute_as, api_call_source)\u001b[0m\n\u001b[0;32m    676\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[0;32m    677\u001b[0m     ne \u001b[39m=\u001b[39m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[0;32m    678\u001b[0m         pe\n\u001b[0;32m    679\u001b[0m     )\n\u001b[1;32m--> 680\u001b[0m     \u001b[39mraise\u001b[39;00m ne\u001b[39m.\u001b[39mwith_traceback(tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m     raised \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\stored_procedure.py:653\u001b[0m, in \u001b[0;36mStoredProcedureRegistration._do_register_sp\u001b[1;34m(self, func, return_type, input_types, sp_name, stage_location, imports, packages, replace, if_not_exists, parallel, strict, source_code_display, statement_params, execute_as, api_call_source)\u001b[0m\n\u001b[0;32m    651\u001b[0m raised \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 653\u001b[0m     create_python_udf_or_sp(\n\u001b[0;32m    654\u001b[0m         session\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m    655\u001b[0m         return_type\u001b[39m=\u001b[39;49mreturn_type,\n\u001b[0;32m    656\u001b[0m         input_args\u001b[39m=\u001b[39;49minput_args,\n\u001b[0;32m    657\u001b[0m         handler\u001b[39m=\u001b[39;49mhandler,\n\u001b[0;32m    658\u001b[0m         object_type\u001b[39m=\u001b[39;49mTempObjectType\u001b[39m.\u001b[39;49mPROCEDURE,\n\u001b[0;32m    659\u001b[0m         object_name\u001b[39m=\u001b[39;49mudf_name,\n\u001b[0;32m    660\u001b[0m         all_imports\u001b[39m=\u001b[39;49mall_imports,\n\u001b[0;32m    661\u001b[0m         all_packages\u001b[39m=\u001b[39;49mall_packages,\n\u001b[0;32m    662\u001b[0m         is_temporary\u001b[39m=\u001b[39;49mstage_location \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    663\u001b[0m         replace\u001b[39m=\u001b[39;49mreplace,\n\u001b[0;32m    664\u001b[0m         if_not_exists\u001b[39m=\u001b[39;49mif_not_exists,\n\u001b[0;32m    665\u001b[0m         inline_python_code\u001b[39m=\u001b[39;49mcode,\n\u001b[0;32m    666\u001b[0m         execute_as\u001b[39m=\u001b[39;49mexecute_as,\n\u001b[0;32m    667\u001b[0m         api_call_source\u001b[39m=\u001b[39;49mapi_call_source,\n\u001b[0;32m    668\u001b[0m         strict\u001b[39m=\u001b[39;49mstrict,\n\u001b[0;32m    669\u001b[0m     )\n\u001b[0;32m    670\u001b[0m \u001b[39m# an exception might happen during registering a stored procedure\u001b[39;00m\n\u001b[0;32m    671\u001b[0m \u001b[39m# (e.g., a dependency might not be found on the stage),\u001b[39;00m\n\u001b[0;32m    672\u001b[0m \u001b[39m# then for a permanent stored procedure, we should delete the uploaded\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[39m# python file and raise the exception\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[39mexcept\u001b[39;00m ProgrammingError \u001b[39mas\u001b[39;00m pe:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\_internal\\udf_utils.py:694\u001b[0m, in \u001b[0;36mcreate_python_udf_or_sp\u001b[1;34m(session, return_type, input_args, handler, object_type, object_name, all_imports, all_packages, is_temporary, replace, if_not_exists, inline_python_code, execute_as, api_call_source, strict, secure)\u001b[0m\n\u001b[0;32m    681\u001b[0m     strict_as_sql \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mSTRICT\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m strict \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    683\u001b[0m     create_query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    684\u001b[0m \u001b[39mCREATE\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m OR REPLACE \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mreplace\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}\u001b[39;00m\n\u001b[0;32m    685\u001b[0m \u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39mTEMPORARY\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mis_temporary\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39mSECURE\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39msecure\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mobject_type\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39mIF NOT EXISTS\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39mif\u001b[39;00m\u001b[39m \u001b[39mif_not_exists\u001b[39m \u001b[39m\u001b[39melse\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mobject_name\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00msql_func_args\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39m{\u001b[39;00minline_python_code_in_sql\u001b[39m}\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m--> 694\u001b[0m     session\u001b[39m.\u001b[39;49m_run_query(create_query, is_ddl_on_temp_object\u001b[39m=\u001b[39;49mis_temporary)\n\u001b[0;32m    696\u001b[0m     \u001b[39m# fire telemetry after _run_query is successful\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     api_call_source \u001b[39m=\u001b[39m api_call_source \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_internal.create_python_udf_or_sp\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\session.py:1142\u001b[0m, in \u001b[0;36mSession._run_query\u001b[1;34m(self, query, is_ddl_on_temp_object)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_query\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m, is_ddl_on_temp_object: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Any]:\n\u001b[1;32m-> 1142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrun_query(query, is_ddl_on_temp_object\u001b[39m=\u001b[39;49mis_ddl_on_temp_object)[\n\u001b[0;32m   1143\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     ]\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:100\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m     97\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m--> 100\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:94\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[0;32m     93\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     95\u001b[0m \u001b[39mexcept\u001b[39;00m ReauthenticationRequest \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[39m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[0;32m     97\u001b[0m         ex\u001b[39m.\u001b[39mcause\n\u001b[0;32m     98\u001b[0m     )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:337\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    335\u001b[0m     query_id_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m [queryID: \u001b[39m\u001b[39m{\u001b[39;00mex\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(ex, \u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    336\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to execute query\u001b[39m\u001b[39m{\u001b[39;00mquery_id_log\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mex\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 337\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n\u001b[0;32m    339\u001b[0m \u001b[39m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[39m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[39mif\u001b[39;00m block:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\snowpark\\_internal\\server_connection.py:321\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[1;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39m_statement_params\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m--> 321\u001b[0m     results_cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cursor\u001b[39m.\u001b[39;49mexecute(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnotify_query_listeners(\n\u001b[0;32m    323\u001b[0m         QueryRecord(results_cursor\u001b[39m.\u001b[39msfqid, results_cursor\u001b[39m.\u001b[39mquery)\n\u001b[0;32m    324\u001b[0m     )\n\u001b[0;32m    325\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExecute query [queryID: \u001b[39m\u001b[39m{\u001b[39;00mresults_cursor\u001b[39m.\u001b[39msfqid\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mquery\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\connector\\cursor.py:827\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream, num_statements)\u001b[0m\n\u001b[0;32m    823\u001b[0m     is_integrity_error \u001b[39m=\u001b[39m (\n\u001b[0;32m    824\u001b[0m         code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m100072\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    825\u001b[0m     )  \u001b[39m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[0;32m    826\u001b[0m     error_class \u001b[39m=\u001b[39m IntegrityError \u001b[39mif\u001b[39;00m is_integrity_error \u001b[39melse\u001b[39;00m ProgrammingError\n\u001b[1;32m--> 827\u001b[0m     Error\u001b[39m.\u001b[39;49merrorhandler_wrapper(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection, \u001b[39mself\u001b[39;49m, error_class, errvalue)\n\u001b[0;32m    828\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\connector\\errors.py:275\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrorhandler_wrapper\u001b[39m(\n\u001b[0;32m    254\u001b[0m     connection: SnowflakeConnection \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m],\n\u001b[0;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    259\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \n\u001b[0;32m    261\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39m        exception to the first handler in that order.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 275\u001b[0m     handed_over \u001b[39m=\u001b[39m Error\u001b[39m.\u001b[39;49mhand_to_other_handler(\n\u001b[0;32m    276\u001b[0m         connection,\n\u001b[0;32m    277\u001b[0m         cursor,\n\u001b[0;32m    278\u001b[0m         error_class,\n\u001b[0;32m    279\u001b[0m         error_value,\n\u001b[0;32m    280\u001b[0m     )\n\u001b[0;32m    281\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m handed_over:\n\u001b[0;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m Error\u001b[39m.\u001b[39merrorhandler_make_exception(\n\u001b[0;32m    283\u001b[0m             error_class,\n\u001b[0;32m    284\u001b[0m             error_value,\n\u001b[0;32m    285\u001b[0m         )\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\connector\\errors.py:330\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     cursor\u001b[39m.\u001b[39mmessages\u001b[39m.\u001b[39mappend((error_class, error_value))\n\u001b[1;32m--> 330\u001b[0m     cursor\u001b[39m.\u001b[39;49merrorhandler(connection, cursor, error_class, error_value)\n\u001b[0;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39melif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\College\\7374\\Assignment 3\\env\\lib\\site-packages\\snowflake\\connector\\errors.py:209\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_errorhandler\u001b[39m(\n\u001b[0;32m    193\u001b[0m     connection: SnowflakeConnection,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m     error_value: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[0;32m    197\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Default error handler that raises an error.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m        A Snowflake error.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(\n\u001b[0;32m    210\u001b[0m         msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmsg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    211\u001b[0m         errno\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39merrno\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    212\u001b[0m         sqlstate\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msqlstate\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    213\u001b[0m         sfqid\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msfqid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    214\u001b[0m         done_format_msg\u001b[39m=\u001b[39merror_value\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone_format_msg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    215\u001b[0m         connection\u001b[39m=\u001b[39mconnection,\n\u001b[0;32m    216\u001b[0m         cursor\u001b[39m=\u001b[39mcursor,\n\u001b[0;32m    217\u001b[0m     )\n",
      "\u001b[1;31mSnowparkSQLException\u001b[0m: (1304): 01ab085c-3200-b026-0000-00027c064021: 391529 (42501): SQL compilation error: Anaconda terms must be accepted by ORGADMIN to use Anaconda 3rd party packages. Please follow the instructions at https://docs.snowflake.com/en/developer-guide/udf/python/udf-python-packages.html#using-third-party-packages-from-anaconda."
     ]
    }
   ],
   "source": [
    "session.use_warehouse('snowpark_opt_wh')\n",
    "train_model_sp = F.sproc(train_model, session=session, replace=True, is_permanent=True, name=\"xgboost_sproc\", stage_location=\"@ml_models\")\n",
    "# Switch to Snowpark Optimized Warehouse for training and to run the stored proc\n",
    "train_model_sp(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch back to feature engineering/inference warehouse\n",
    "session.use_warehouse('FE_AND_INFERENCE_WH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import cachetools\n",
    "import joblib\n",
    "from snowflake.snowpark import types as T\n",
    "\n",
    "session.add_import(\"@ml_models/model.joblib\")  \n",
    "\n",
    "features = [ 'C_BIRTH_YEAR', 'CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS', 'CD_DEP_COUNT']\n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "@F.pandas_udf(session=session, max_batch_size=10000, is_permanent=True, stage_location='@ml_models', replace=True, name=\"clv_xgboost_udf\")\n",
    "def predict(df:  T.PandasDataFrame[int, str, str, str, str, str, int]) -> T.PandasSeries[float]:\n",
    "       m = read_file('model.joblib')       \n",
    "       df.columns = features\n",
    "       return m.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = session.table('feature_store')\n",
    "inference_df = inference_df.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "inputs = inference_df.drop(\"TOTAL_SALES\")\n",
    "snowdf_results = inference_df.select(*inputs,\n",
    "                    predict(*inputs).alias('PREDICTION'), \n",
    "                    (F.col('TOTAL_SALES')).alias('ACTUAL_SALES')\n",
    "                    )\n",
    "snowdf_results.write.mode('overwrite').save_as_table('predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('snowpark_xgboost_tpc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "353961104846001ffa111d7d98923933ef13c251c8e9b3ebc563f652eb6b45f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
